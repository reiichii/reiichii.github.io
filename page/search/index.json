[{"content":"前回の記事の続きです。\nISUCON12 予選の解説 (Node.jsでSQLiteのまま10万点行く方法) : ISUCON公式Blogを参考にPythonで解き直していました。アプリケーションサーバを分ける手前まで改善したのですがmax6500点までしかいかず、分けても10万点どころか予選突破相当の24000点に届くかさえ怪しかったので頓挫しました。\n追加で実施できたもの\ntenantDB player_scoreにINDEXをはる Ranking APIでランキング集計するのをやめる 自分で追加で行ったこと\nscoreエンドポイントのトランザクション見直し Finish APIでBillingReportを生成する の修正 lockによるエラーが多発したので一旦timeoutを伸ばす players/addの改善 実施しなかったもの\nAddTenant APIでSQLite DBを作るのをやめる nginxで複数台に振り分ける nginxをupstream keepaliveする MySQLをちょっとチューニングする scoreエンドポイントのトランザクション見直し 整合性チェック時に3回に1回くらいの頻度でエラーが発生していたので修正に着手しました。 AUTOCOMMITの設定がちゃんと効いていなかった模様。sqlalchemyはデフォルトでautocommitが効いており、scoreの時だけ設定を上書きするようにしました。\nコミットログ\nエラー解消が目的だったのでスコアに影響はありませんでした。\n参考\nTransactions and Connection Management — SQLAlchemy 1.4 Documentation SQLAlchemyのautocommitについて - Qiita Finish APIでBillingReportを生成する の修正 整合性チェックは通るのですがベンチマーク全体の中で1~3回ほど GET /api/organizer/billing 請求レポートの数が違います (want: 5, got: 1)のようなエラーが出る。 のようなエラーが出る状態でした。\n終わっていない大会の情報も出してあげる必要があったのですが、それらの情報がDBには存在していないのが原因でした。存在しなければscore等を0を入れてレスポンスデータを生成します。\nコミットログ\n上記二つを行なってエラーもなくなり、スコアが安定するようになりました。ただし負荷走行中にSQLite3でlockエラーが多発するようになりました。\ntenantDB player_scoreにINDEXをはる 初期化時にinitial_dataをtenant_db配下にコピーしているのでinitial_dataのテーブルに対してINDEXを追加します。 テナントごとにdbがあるのでシェルでまとめて適用してあげます（ブログに書いてあったコマンドをそのまま実行しました）\nクエリ：create index idx_score on player_score (tenant_id, competition_id, player_id);\nfor db in *.db; do echo \u0026quot;CREATE INDEX...\u0026quot; | sqlite3 $db; done\nちなみにplayer_score以外のテーブルはデータ量が100件程度しかなく、貼っても意味なさそうなのでそのままにしました。 SQLite3の実行計画は クエリの頭にEXPLAIN QUERY PLAN を付けます。\n# player/\u0026lt;player_id\u0026gt;時 EXPLAIN QUERY PLAN SELECT c.title AS title, p.score AS score FROM player_score AS p INNER JOIN competition AS c ON c.id = p.competition_id WHERE c.tenant_id = ? AND p.player_id = ? ORDER BY c.created_at ASC # 結果 |--SCAN p |--SEARCH c USING INDEX sqlite_autoindex_competition_1 (id=?) `--USE TEMP B-TREE FOR ORDER BY 点数は500点ほど上がったのですが、それ以上にDBのlockによるエラーがひどく、41%失点している有様でした。\nlockによるエラーが多発したので一旦timeoutを伸ばす タイムアウトを伸ばすしか思い浮かばなかったのでデフォルト値を調べてみることにしました。\nソースコードを見た感じPythonのSQLite3の標準ライブラリの設定がそのまま反映されているようでそれが5sでした。 30sに設定してみたところlockによる500エラーは大幅に減らせました。ただしclient側でconnection timeoutが発生しているのですがひとまず1件程度まで抑えられたので一旦よしとしました。\nコミットログ\nRanking APIでランキング集計するのをやめる ranking APIの呼び出される回数とscoreが入稿される回数は10～20倍くらい差がある rankingはscoreを入稿したときしか変わらない\n言われてみれば確かに。\n大会中にこのボトルネックに気づいていたらまず間違いなくDELETE+bulk insertで対処していたと思うのですが、 ON DUPLICATE KEY UPDATE を初めて知ったのでこっちで実装してみることにしました。\nON DUPLICATE KEY UPDATE ON DUPLICATE KEY UPDATE を指定した時、UNIQUEインデックスまたは PRIMARY KEY に重複した値を発生させる行が挿入された場合、mysqlによって古い行の値が実行される 存在していればupdate する やることとしては以下です。\nrankingテーブルを作成する CREATE TABLE ranking ( `tenant_id` BIGINT UNSIGNED NOT NULL, `competition_id` VARCHAR(255) NOT NULL, `rank` INT NOT NULL, `score` BIGINT NOT NULL, `player_id` VARCHAR(255) NOT NULL, `player_display_name` TEXT NOT NULL, PRIMARY KEY (`tenant_id`, `competition_id`, `rank`) ) ENGINE=InnoDB DEFAULT CHARACTER SET=utf8mb4; row_numは不要だから消したと思われる。competition_idさえ分かればtenant_idはなくても良さそうに思える scoreエンドポイントでrankingを生成し、insertする 初期化対応 が必要とのことでしたが、データを入れ直さなくてもベンチマークが通ったのでしませんでした。データが溜まっていってしまうのを防ぐために削除だけ行うように修正しました。 コミットログ\nベンチマークを何度か実行していたのですが6500~5600と振り幅が大きい\u0026hellip;。\nplayers/addの改善 alpの結果を眺めていたら上記エンドポイントが異常に重たくなっていました。スコアログを見返すとflockをトランザクションにしたあたりからずっとひどい状態でした笑\nスコアが伸び悩んでいたのもあり、気になったので改善してみようとコードを読んだら、こちらもfor文の中で逐一クエリが発行されていました。sqliteの負荷が懸念だったのもあり以下のようにそれぞれまとめて取得してPython側で頑張るように修正しました。\nコミットログ\nalpを見た感じ改修の効果は得られた(25s→2sになった)のですが、点数には影響せず\u0026hellip;。\nおわりに 10万はいかなくとも2万くらいはいきたいなと思っていたのですが、今のまま複数台分散してもそこまで上がる見込みがなく、だれてきてしまったのもあり一旦一区切りにしようと思います😓\n全体の改善のログは以下に。\nスコア推移のログ · Issue #1 · reiichii/isucon12q-after\nISUCON11予選問題解説のやり方を参考に残していました。\n","date":"2022-09-04T22:28:00+09:00","permalink":"https://reiichii.github.io/post/2022-09-04-22/","title":"ISUCON12予選問題解き直し2"},{"content":"8月はISUCON12 予選の解説 (Node.jsでSQLiteのまま10万点行く方法) | ISUCON公式Blogを見ながらISUCON12予選問題の解き直しをしていました。まだ全部施策をやり切れておらず、点数も上がりきってはいないのですが、1ヶ月経ったので途中までまとめることに。\n実施できたもの\nadminDB visit_history にINDEXを張る dispenseIDでMySQLを使うのをやめる Ranking APIのループクエリをなくす Score APIの追加のループクエリをなくす アトミック書き込みのためのflockをトランザクションに変更する(※怪しい) adminDB visit_historyの初期データをコンパクトにする db用サーバを投入し、2台構成にする Finish APIでBillingReportを生成する(※怪しい) Player APIをなんとかする まだできていないもの\ntenantDB player_scoreにINDEXをはる Ranking APIでランキング集計するのをやめる AddTenant APIでSQLite DBを作るのをやめる nginxで複数台に振り分ける nginxをupstream keepaliveする MySQLをちょっとチューニングする 半分以上は実施しているのに未だ点数が6000点代という\u0026hellip;思ったより厳しかった。\nadminDB visit_history にINDEXを張る 去年の問題ならinitialエンドポイントテーブルが作り直しているのでschemaにindexを追加していたのですが、今回は対象テーブルではdrop createは実行されていないのでここに書いても意味なかったという🙂\ncovering indexという概念を初めて知りました。indexって貼れていればいいと思っていたのですが、張り方によっても性能(点数)に差が出てしまうんですね。せっかくなので3パターンで実行計画を比較してみました。\n# 既存 EXPLAIN SELECT player_id, MIN(created_at) AS min_created_at FROM visit_history WHERE tenant_id = 1 AND competition_id = \u0026#39;S\u0026#39; GROUP BY player_id; +----+-------------+---------------+------------+------+---------------+---------------+---------+-------+---------+----------+------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------------+------------+------+---------------+---------------+---------+-------+---------+----------+------------------------------+ | 1 | SIMPLE | visit_history | NULL | ref | tenant_id_idx | tenant_id_idx | 8 | const | 1292937 | 10.00 | Using where; Using temporary | +----+-------------+---------------+------------+------+---------------+---------------+---------+-------+---------+----------+------------------------------+ # covering index +----+-------------+---------------+------------+------+-----------------------------+---------------+---------+-------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------------+------------+------+-----------------------------+---------------+---------+-------------+------+----------+-------------+ | 1 | SIMPLE | visit_history | NULL | ref | tenant_id_idx,idx_all_cover | idx_all_cover | 1030 | const,const | 1 | 100.00 | Using index | +----+-------------+---------------+------------+------+-----------------------------+---------------+---------+-------------+------+----------+-------------+ # createdなし +----+-------------+---------------+------------+------+-----------------------------+---------------+---------+-------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+---------------+------------+------+-----------------------------+---------------+---------+-------------+------+----------+-------+ | 1 | SIMPLE | visit_history | NULL | ref | tenant_id_idx,idx_all_cover | idx_all_cover | 1030 | const,const | 1 | 100.00 | NULL | +----+-------------+---------------+------------+------+-----------------------------+---------------+---------+-------------+------+----------+-------+ indexを追加すると、possible_keys,keyにidx_all_coverが追加され、filteredが100%になる covering indexにすると、ExtraにUsing indexが表示される createdありとなしではスコアには200点ほど差がでた mysqlのconvering indexとは\nクエリーによって取得されたすべてのカラムを含むインデックス 検索を索引内で完結でき、表からデータを読み取る必要がないため効率が良い 表のサイズがメモリに保持しきれないほど大きい場合の検索で有効 +500点ほど\ndispenseIDでMySQLを使うのをやめる 一意なidを生成するために以下のようにわざわざDBにアクセスしているが、これをuuidを生成するようにする\nコミットログ\nSQLのREPLACE INTOとは\n基本INSERTと同じだが、テーブル内の古い行にprivary keyまたはuniqueインデックスに関して新しい行と同じ値が含まれている場合その古い行は新しい行が挿入される前に削除される 挿入 or 削除と挿入　の違い raise fromについて\n例外を連鎖することができる try: raise ConnectionError() except ConnectionError as e: raise RuntimeError(\u0026#34;Failed to open database\u0026#34;) from e 出力は以下：The above exception was the direct cause of the following exception Traceback (most recent call last): File \u0026#34;~/ghq/github.com/reiichii/isucon12q-after/tmp.py\u0026#34;, line 2, in \u0026lt;module\u0026gt; raise ConnectionError() ConnectionError The above exception was the direct cause of the following exception: Traceback (most recent call last): File \u0026#34;/~/ghq/github.com/reiichii/isucon12q-after/tmp.py\u0026#34;, line 4, in \u0026lt;module\u0026gt; raise RuntimeError(\u0026#34;Failed to open database\u0026#34;) from e RuntimeError: Failed to open database from を使わないと、During handling of the above exception, another exception occurred のようになる +200点ほど\nRanking APIのループクエリをなくす リクエストの合計時間が一番長い /api/player/competition/\u0026lt;competition_id\u0026gt;/ranking をなんとかする。\nN+1になっているのでjoinを使う。\nコミットログ\n+1000点になりました😳\nScore APIの追加のループクエリをなくす rankingの次にレスポンスタイム合計が大きいのはscoreなので\nNode.jsで解いていたブログ記事では上記のように書いてあったが、私の環境(Python)ではscoreよりも/api/player/player/\u0026lt;player_id\u0026gt; の方が重かったです。\n自分では最後のinsertのところをbulk insertにすればいいのかなと思っていたが、存在しないplayer_idを返す必要はないので数を比較するだけで十分という考えには至れませんでした。\nコミットログ\nこちらも+1000点ほど\nアトミック書き込みのためのflockをトランザクションに変更する(※怪しい) 既存コードではテナントDB更新の際に、排他制御をするためにファイルをロックすることをしていますが、トランザクションを使うようにします。 delete-insertの部分をトランザクションにしてflockを外す。他のflockは参照のみなので外すだけで良かった。\nコミットログ\nこの部分を実装したところ、数回に1回整合性チェックが通らなくなりました😢おそらくトランザクションがちゃんと効いていない模様で、なんでか全然分からなかったのですがおそらくAuto Commitが効いてしまっているところに思い至ったのでこれから確認する段階です。\nそしてなぜか点数はそれほど上がらないどころか実行するたびに数百点の振り幅が出るように。\nadminDB visit_historyの初期データをコンパクトにする アプリケーションの作りがアクセスしたかどうかが分かればいいため、visit_historyのテナントID、大会ID、プレイヤーIDをgroup byしてmin(created_at) / min(updated_at)のデータのみが残るようにして重複したデータを減らす。\nちなみに対象テーブルのMySQLの初期化の部分は以下のようになっていて、一定のデータが消えないようになっています。\nDELETE FROM visit_history WHERE created_at \u0026gt;= \u0026#39;1654041600\u0026#39;; 念の為既存データを残しておきたかったので、私は以下の手順で実施しました。\n一時テーブルを作成（visit_history_tmpとする） INSERT SELECT INSERT INTO visit_history_tmp SELECT player_id, tenant_id, competition_id, MIN(created_at), MIN(updated_at) FROM visit_history GROUP BY 1,2,3; 古いテーブルをrename RENAME TABLE visit_history TO visit_history_backup; 一時テーブルをvisit_historyにrename RENAME TABLE visit_history_tmp TO visit_history; 初期化時点の行数：3,224,839 → 削減後のデータ数：200,474（0.06%にまで削減された）\nただし私の場合スコアは変わらず\nDB用サーバを投入し、2台構成にする ブログの方では複数台構成準備のための施策に突入するのですが、私は先にappとdbの二台構成にすることにしました。\nmysqlで他サーバからのアクセスを許容する CREATE USER `isucon`@`192.168.%` IDENTIFIED BY \u0026#39;isucon\u0026#39;; GRANT ALL PRIVILEGES ON `isuports`.* TO `isucon`@`192.168.%`; application側で参照先dbを変更 今回はdocker-composeにホストが書いてあったのでそこの値を変更する 前のベンチマークの時点でCPUが余っていたので、これやっても点数が大して変わらないのは予想通りでした。\nFinish APIでBillingReportを生成する 今回の当日マニュアルにあった、「Finish APIを呼び出したあとにAdmin/OrganizerのBilling APIに結果が反映されるまで3秒の猶予があるの意味は、「初期実装だとBilling APIで請求額を計算しているけど、大会ごとにfinishするときに大会の請求額が確定するので、BillingReportをそこで生成してストレージにいれてね!」です。\n分からん\u0026hellip;😇\nfinish が呼ばれた時にbilling_report_by_competitionを呼び出して、その結果をinsertします。\nテーブルを作成 CREATE TABLE `billing_report` ( `tenant_id` BIGINT UNSIGNED NOT NULL, `competition_id` VARCHAR(255) NOT NULL, `competition_title` VARCHAR(255) NOT NULL, `player_count` BIGINT NOT NULL, `visitor_count` BIGINT NOT NULL, `billing_player_yen` BIGINT NOT NULL, `billing_visitor_yen` BIGINT NOT NULL, `billing_yen` BIGINT NOT NULL, PRIMARY KEY(`tenant_id`, `competition_id`) ) ENGINE=InnoDB DEFAULT CHARACTER SET=utf8mb4; finish apiの時にbilling_report_by_competitionを呼び出して結果をinsertする admin/organizationのbillingの参照先をdbからselectして取ってくる 初期データ生成処理を改修 初期データを入れ直したあとに全ての終了済み大会について billingReportByCompetition を実行してINSERTしなおす必要がある billing report初期データ生成スクリプトを作成 mysqldump -uroot -proot isuports billing_report \u0026gt; initial_billing_report.dump initial時に初期データをimportさせる コミットログ\nスコアはそれほど変わらず、不安定さが増してしまったように見受けられました。(編集とは関係ないエンドポイントでエラーが発生する) ただapi/admin/tenants/billing, api/organizer/billingの呼び出し回数と合計レスポンスタイムが大幅に改善されているので一旦よしとします。\nPlayer APIをなんとかする 上記のメトリクスを眺めているときにPlayer APIがものすごく重たくなっている(MAX 5s程度だったものがMAX 30sになっていた笑)ことに気づき、あまりにも気になったので先に直すことにしました。\nコミットログ\nこれもN+1を直すだけです。必要な情報に対して多くクエリを発行しているのでスリムに書き直してあげます。\n今まで4000点代で伸び悩んでいたスコアが6000点台まで届きました👏\nおわりに スコアが伸び悩んで、また他のことをやりたくなってきたのもあり、8月いっぱいで一旦やめにしようかなと思いかけていたのですが、月末の週に突入して解決の兆しが見えてきたので、もう少し粘ってみようかと思います。\n複数台構成にしたら10万点まで届くのだろうか\u0026hellip;\n続きも書けたら書きます。\n","date":"2022-08-27T14:57:37+09:00","permalink":"https://reiichii.github.io/post/2022-08-27-15/","title":"ISUCON12予選問題解き直し"},{"content":"ISUCON12予選に参加しました。結果は散々だったのですが振り返りも兼ねて残しておこうと思います。\nISUCON12 オンライン予選、17:00の時点でスコアは凍結されました🚀 残時間 01:00:00のスコアはこちら！ #isucon pic.twitter.com/SGjrF9nBCR\n\u0026mdash; ISUCON公式 (@isucon_official) July 23, 2022 ステータス 初出場 Python 1人チーム 2502点 目標は「闇雲に手を動かずに爪痕残す」でした。 爪痕は残せませんでした🪦\n準備 やっていたこととしては以下です。\nISUCON11予選過去問解く alpやmysqlのslow query logなどの計測ツールを使えるようになっておくこと 6月に行われた事前講習とハンズオンへの参加 普段rubyさわらないので多少やりにくかったのですが、出て良かったです。 ISUCON用ansible playbookを用意 計測ツールの導入をスムーズに行うため準備していました タイムライン 09:40~ 配信視聴 予選問題の概要を聞く 10:00~ 開始 ポータルサイト一通り見る（感動した） 当日レギュレーションを読む マニュアルを読む 読みながらアプリケーションを触ったり、ユースケース図を書いて仕様を把握 サーバへのssh接続確認 11:00~ 準備 ソースコードをgit管理下に置く 初回ベンチマークを実行 フワッと改善の目星をつける サーバ構成をmysql用サーバとapplication用の2台構成に変更する 12:00~ 準備 計測ツールの導入 nginxの設定ファイルをgit管理下に配置し直す 13:00~13:30 お昼休憩 20分でご飯食べて10分昼寝。もうこの時点で結構疲れていた 午前中はアプリケーションコードをほとんど見れていない 13:30~ 準備の延長戦 nginxの設定ファイルを間違えており、修正箇所探しに時間を潰す 14:00~ 改善開始 アプリケーションのコードを眺める 14:30~16:30 改善案1.スロウクエリを潰す試み 16:30~17:30 改善案2.リクエスト数の多いエンドポイントの改善 17:30~ 改善案3.bulkinsertに書き換えてみる 17:45~ 再起動チェック 18:00~19:00 競技終了・配信で講評を聞く こうして振り返ってみると計測ツールをスムーズに導入できていれば+1hくらいコード読む時間を捻出できていましたね。ansibleを用意していたがちょこちょこ小さいエラーにはまって気がついたら1hほど経ってしまっていました。\n今回の目標が闇雲に手を動かさないだったので、一応自分なりに根拠や狙いを持っていたつもりだったのですが、講評を聞く感じ的が外れていました。\n改善案0.サーバの役割分担 サーバ構成をmysql用サーバとapplication用の2台構成に変更しました。\n初回ベンチ実行時にtopの出力を眺めていたのですが、dbとpythonがcpuを食い潰しあっているように見えたため。先に分けた方が今後変化追いやすいかなと思ったというのもあります。\n分けたことにより+500点ほどスコアが改善しました。goからpythonにしたときに下がった分が元に戻っただけなので実質プラマイ0ですね。\n改善案1.料金集計処理のスロウクエリを潰す試み adminとorg系リクエストの配点が高いこと adminの一覧画面とorgの請求情報一覧画面が異様に重かったこと スロウクエリログで一番重かったクエリが、上記二つのリクエスト時に実行されるクエリだったこと から、この処理を改善すればパフォーマンスが大きく改善するのではと着手することにしました。\nそれ自体は良かったのですが、 処理が参照しているデータ源がmysqlとsqliteに分かれていることからどうしたら良いものかと手が動かず。sqliteをmysqlに載せ替えるといった選択肢は効果が見込めるかどうか分からなかったので実施に踏み切れませんでした。\nmysql側の改善をしようと検索件数を必要な分だけに絞ったりしていたのですが、ベンチマーカーによる整合性チェックでエラーが出てしまいました。この処理の改善に2hほどかけてしまっていたので中断することにしました。\nログ\n改善案2. playerのリーダーボード一覧エンドポイントを改善する試み alpでリクエストを集計したところ合計レスポンスタイムが一番多かったのはplayerのリーダーボード一覧エンドポイントだったこと ベンチマーカーの出力に「leaderboardの表示に1秒以上かかったため2人の参加者が離脱しました。」のように出ていたこと player系エンドポイントは、先ほどのadminやorg系エンドポイントと異なり加算は少ないのですが、上記の理由からここを改善すれば少なくともスコアがそれなりに改善される見込みがありました。\nただ参照先がsqliteのデータで、パフォーマンス改善ってどうやるんだと首を捻る羽目に。調べてみたらsqliteにもインデックスの概念があり、DB初期化スクリプトのcreate table sql見たところインデックスは貼られていなかったので試しに貼って見たのですが、ほとんどスコアに影響はありませんでした。\nまだ改善の余地はあったのかもですが、この時点で残り1hを切ってしまっていたため一旦深追いをやめてしまいました。\nログ\n改善案3. forでinsertしている箇所をbulkinsertさせる 残り時間が微妙だったので、ソースコード眺めているときに気になっており、すぐに改善できそうな箇所として /api/organizer/players/add のinsert処理を書き換えようと思いました。実施して見たもののベンチマーカーがこけました。単純に書き換えるだけだと後続処理が意図した形に動かなかくなってしまうことに後から気づきました。\nそもそもアプローチ方法が間違えていたのか、後続処理も合わせてなんとかする余地があったのか、残りが15分と検討する時間がもうなかったので中断しました。\nログ\n問題の所感 「mysqlで準備していたからpostgresqlとかだったらきついな..まあスポンサーにmysqlがいるからないか」とか思っていたらまさかのmysql+sqliteでびっくり auto_incrementのところも何か変なコードがあるなぁとは思っていたのですが、料金表とリーダーボード表示の箇所にばかり気を取られていたので全然見れませんでした 講評で「インデックスを貼ればdbの負荷がひとまずは下がる」ようなことが言われていて、もう少しDB周りを重点的に確認すれば良かったです。見ていた箇所のクエリのインデックスは確認していたつもりだったのですがそうではなく、出てきたスロークエリに対してインデックスが効いているかを見ておくべきでした lockがやたら多いのも気にはなっていたのですが、トランザクションを使う箇所というのが出てきませんでした。ただの知見不足です ユースケース図を書いていたのですが、アプリの全体像を網羅的に把握するのに役立ちました。アプリケーションとdbのやりとり周りも何かしらの方法でスムーズに把握できるようになれると良かったのですが その他感想 ISUCON11予選問題を解いていた時はアプリケーションの使用の仕様が難しく、何やっていいか全く分からない状態でした。それに比べたら今回の問題はまだその辺りの把握はしやすかったです ポータルサイトがどんなものかずっと見てみたかったので感動しました。終わった後速攻で選手用ページが見れなくなってしまい、ベンチマークのログやダッシュボードのスクショを取り損ねてしまいました 終わった後眼精疲労でくたくたで、速攻でpc閉じてしまったのですが、DCの方では感想戦で盛り上がっていて他の参加者のバイタリティの高さを感じました。翌朝読み返していて面白く、復習時の参考にまた読み返そうと思います 集中力は8h意外と持ちました。1h~1h30minにつき5minの休憩を無理やり設けるようにして良かったです おわりに 無念 : 楽しかった！ が 6:4の気持ちです。\nあと目と手と頭が足りないです。本戦一人出場している人の凄さを実感します。私がアプリケーション側でもう少しまともに戦えるようになったら、次回は誰か誘ってみるのもありかもなと思えてしまいました。\n今年もPythonでの本戦出場選手は出なかったのでPythonで狙いたいなと思う反面、業務で触らないgoの勉強の口実にしたいという気持ちのが強いので、来年はgoで10000点以上出すことを目標に出てみたいと思います。ベンチマーカーがgoで書かれていて、その辺りの処理ももう少し読めるようになりたいんですよね。\n運営の皆様、開催ありがとうございました。\nhttps://github.com/reiichii/isucon12-qualify\n計測ログ\n","date":"2022-07-24T14:06:01+09:00","image":"https://reiichii.github.io/post/2022-07-24-14/score_graph_hu1c45c6ba752b88bcb48fca24fcaa2fcb_322845_120x120_fill_box_smart1_3.png","permalink":"https://reiichii.github.io/post/2022-07-24-14/","title":"ISUCON12予選参加した"},{"content":"ISUCON11予選環境構築時、構築したアプリケーションでログインしようとすると「このサイトにアクセスできません」が表示されます。また遷移先urlが「http://localhost:5000/?callback=https://isucondition.t.isucon.dev」のようにおかしな表示になります。\n前提として以下の手順を参考に、クラウド環境にアプリケーションを構築し、トップページが開けるところまでを確認済みです。\nISUCON過去問題の環境を「さくらのクラウド」で構築する | さくらのナレッジ\nやること1. JIA API Mockを起動する アプリケーションマニュアルの末尾に書いてあるのですが、サーバの5000portで一部のリクエストを待ち受けるようになっているみたいです。\n実際urlからも分かる通り、apiのログイン時に5000portに飛ばすようになっています。該当コードは以下です。\nhttps://github.com/isucon/isucon11-qualify/blob/main/webapp/frontend/src/components/Home/Auth.tsx#L6\n自動起動はしないため、マニュアルに書いてある手順でモックのサービスを起動してあげます。\nやること2. ポートフォワーディングの設定 このままだとアプリケーションした際にローカル環境の「localhost:5000」にアクセスされてしまいます。\nローカル環境の5000にアクセスされたら、リモートサーバの5000にアクセスされるようにポートフォワーディングの設定をしておきます。\nssh -A -L 5000:{ip}:5000 {user}@{ip}\nssh接続した状態で「JIAのアカウントでログイン」を押すと、「Sign in with JIA」の画面が開き、ユーザー名とパスワードを入力してログイン後の画面にすすめるようになります👏\nおわりに 分かる人には分かるのかもしれませんが、これは構築手順書に説明があった方が親切なような気がしました。\nちなみにこの辺の仕様について話されているissueも発見しました。完全に理解はしていません..。\nhttps://github.com/isucon/isucon11-qualify/issues/1260\n","date":"2022-07-13T22:21:31+09:00","permalink":"https://reiichii.github.io/post/2022-07-13-22/","title":"ISUCON11-qualifyのログインページが開かなかった"},{"content":"ISUCONハンズオン目的で申し込んだのですが、去年一昨年の事前講習レポートには書いていない内容が盛り込まれていて普通に楽しかったです。\nISUCON12 事前講習 - Speaker Deck\nほぼ資料に書いてあるのですが、記念に手元のメモも残します。\n## 強いチームがしていること * なんとなくで手を動かさない。 - 優勝者インタビューで「何が効いたのかわからない」というチームはいない * デプロイのリードタイムをに1分以上かけない - GUIでgit操作しがちなご時世だけど、gitコマンドを使った方がいいよ * 使い慣れたミドルウェアのconfigを1から書かない - 事前に用意しておく * やったことがないことをやらない - 大会中に実務で触っていないgoに移植しようとしてボロ負けした経験がある なんとなく手を動かすな、仮説をベースに動くことはISUCON以外の仕事でも言える。\n## タイムライン 10:00 * マニュアルとレギュレーションを読む * ブラウザでサービスを見て、アプリケーションを把握する * 各コンポートネントがどう起動されているか、設定やconfigの場所を確認 - init.dかsystemcnfかdockerかなど * 自分が必要なruntimeをさっとインストールできるようにしておく * dbスキーマがどう定義されているか調べる * デプロイ方法を構築する * 使われているミドルウェアの種類とバージョンを調べる - 過去にmemcacheかと思ったらmemcacheのplaginを入れたmysqlでそれがすごく重い、という罠があったらしい * 使っているサーバのスペックを各台調査する - サーバによってスペックが異なるケースがある * ベンチマークを実行する 11:00 * 得点源が何かを確認する * 減点の要因を把握する * プロファイリングツールを入れる * 初期状態の完全なバックアップを作成する - tarで固めておく 12:00 * ちゃんとご飯を食べる * わからないことが出たらリストにしておく * やること、やらないことを明確にする 13:00 * デプロイが1コマンドでできるように * デプロイ→性能計測→プロファイルまで一気通貫で行える仕組みを用意しておく - line_profile - リクエスト単位　どちらも 14:00~17:00 * 1コミット1ベンチマーク * 気にする指標を明確に把握してプロファイルする 17:00 * 再起動試験をする * apmを入れていたら停止する - newrelicのapm止めるの意外と難しかったりする * デバックログの出力を止める * プロファイル用に差し込んだものを止める 18:00 * 作業ログをブログに書く準備をする * 記憶が明確な間に振り返りをする 優勝経験チームの行動をトレスしたタイムラインは、考え方など参考にできるところが多い貴重な資料です。\n前にISUCON11予選過去問に挑戦した時、私の場合マニュアルとレギュレーションを読むだけで1時間はかかったので10:00代きっっっつて思いながら聞いていました🙂\n### おすすめの練習 * デプロイ方法セットアップ - リポジトリ作って、git initして、チェックインして、deploy * ansibleを最速で回せるようになっておく * ベンチマークから集計を1コマンドでできるようにする - 集計スクリプトを作っておく * サーバの役割変更 - 起動を止める(systemctlならdisableし忘れない)、接続先を変更する * 使いたいツールのインストール - 使いたいツールは一発で入れられるようにする(alp,pt-query-digest) - prebuilt binaryが用意できるなら用意するのも手 もし今年出れるなら、最低限これだけは準備していきたい。\nまた最後に同じ問題5回くらい解くと、新しい発見があって楽しいよといったこともあって、また過去問解き直そうと思いました。\nちなみにまだ参加申し込みできていませんorz\n","date":"2022-06-07T20:56:13+09:00","permalink":"https://reiichii.github.io/post/2022-06-07-20/","title":"ISUCON12事前講習"},{"content":"\n1年ほど前にこしらえた自作キーボードでpc作業を行なっています。\n久しぶりにキーマップを変えようと思ったらびっくりするくらいやり方を忘れており、思い出すのに結構時間が掛かったため未来の自分用に忘備録としてやり方を残しておきます。\n【自作キーボード】Sparrow62を組み立てた\nやること キーマップの設計 キーボードのfirmwareに書き込む キーマップの設計 キーマップの設計は、QMK ConfiguratorというWebアプリからGUIで行います。\n前の設定を読み込ませる KEYBOARDを自分が使っているものに選択する urlからjsonをアップロードするボタンを押下し、keymap.json（以前の設定時にexportしておいたもの）のrowファイルのurlを読み込ませる 画面ぽちぽちでキーマップの配置を変更する 右上のCOMPILEボタンを押下する 右下のFIRMWAREボタンを押下し、hexファイルをダウンロードする 後の作業のために、この画面はまだ閉じないでおく。\n参考：（初心者編）QMK Configuratorを使ってキーマップを書き換えよう - 自作キーボード温泉街の歩き方\nキーボードのfirmwareに書き込む ローカルPCにインストール済みのQMK Toolboxに先ほどのhexファイルを読み込ませ、キーボードのfirmwareに書き込みます。キーボードは左右繋げたままにして、左右それぞれに書き込みをします。\nQMK Toolboxを開く 先ほどダウンロードしたhexファイルを読み込ませる autoreloadにチェックをする キーボードのリセットボタンを1度押下する 書き込みが始まり、「done. thank you. disconnect」の文言が出たら無事成功 反対のキーボードにケーブルを差し、3と4を行う QMK ConfiguratorのTEST KEYBOARDでキーボードのボタンに意図した変更が反映されていることを確認する。\n参考：（初心者編）自作キーボードにファームウェアを書き込む - 自作キーボード温泉街の歩き方\n後片付け QMK Configuratorでjsonファイルをexportしておく（次回また読み込ませるため） PRINT KEYMAPで画像をスクショしておく（稀にボタンの配置がどうなっていたのか見返したくなるため） 上記をkeymapリポジトリに反映させておく おわりに 初回は設定で精一杯で運用(?)のことを全然考えていなかったので、「あれjsonファイル出力してたっけ」「キーマップの画像をスクショしておいたはずなんだけどどこやったっけ」なんてわたわたしていました。githubに上げておけば家からでも会社からでもキーマップ確認できるし、これできっと一安心😌\n","date":"2022-06-05T16:19:27+09:00","image":"https://reiichii.github.io/post/2022-06-05-16/img_keymap_hu50b55d9f2e639c377323533322f7b495_75174_120x120_fill_box_smart1_3.png","permalink":"https://reiichii.github.io/post/2022-06-05-16/","title":"キーマップ変更する時の手順"},{"content":"はてなからHugoで立てたブログに引っ越しました。\n大きな理由としては、以前のブログの見た目が気に入らなかった（カスタマイズのコストが高い）ことと、vscodeとmarkdownでブログ書きたかったというのが主です。\nデプロイ先はNetlifyを使おうか悩んだのですが、ブログの目的がアウトプットの習慣付けが主で、アクセス数稼ぎに力を入れていないことと、普段業務でGitLabを使うことが多かったので、GitHub PagesやCICDをちょっと触ってみたいなというのもあり、ミニマムにGitHub Pagesで始めてみることにしました。後から乗り換えることもできなくはないですし。その場合ドメイン変わってしまいますが個人ブログでリスクもないので気の向くままにやっていく方針で😌\n既存のブログと記事は特にexportせずそのまま残しておく予定です。（もしかしたら戻る可能性もなくはないので）\nこれからもマイペースに続けていきたいと思います。\n以前のブログ\n","date":"2022-05-27T17:01:55+09:00","image":"https://reiichii.github.io/post/2022-05-27-16/IMG_8179_hu05940ea99d8537e6bd20faf24b516d8b_1077440_120x120_fill_q75_box_smart1.jpg","permalink":"https://reiichii.github.io/post/2022-05-27-16/","title":"ブログ引っ越した"}]